import re
import json
import subprocess
import datetime
import os
configfile: "config.malva.yaml"


pjoin = os.path.join

ref_config = config["reference"]
vcf_config = config["vcf"]
gtf_config = config["gtf"]
sample_config = config["sample"]

root_dir = config["workdir"]
kmc_dir = pjoin(root_dir, "KMC")
malva_dir = pjoin(root_dir, "malva")
tagvcf_dir = pjoin(root_dir, "tagvcf")
ease_dir = pjoin(root_dir, "easevcf")
snpeff_dir = pjoin(root_dir, "snpeff")
pangolin_dir = pjoin(root_dir, "pangolin")

minocc_config = config["minocc"] if "minocc" in config else 5
maxocc_config = config["maxocc"] if "maxocc" in config else 50000
malvak_config = config["malvak"] if "malvak" in config else 31
cores_config = config["cores"] if "cores" in config else 4
maxmem_config = config["maxmem"] if "maxmem" in config else 4
refname_config = config["refname"] if "refname" in config else None

malva_bf_size = 1 # max(1,int(maxmem_config/3))

status_json_fn = pjoin(root_dir, "status.json")


def update_status(new_status, step_name=None, new_json=None, last_step=False):
    # Load JSON
    try:
        with open(status_json_fn) as json_file:
            data = json.load(json_file)
    except FileNotFoundError as e:
        data = {}

    # Update status and steps
    data["status"] = new_status
    data["last_time"] = nowf()
    if new_json:
        if "steps" not in data:
            data["steps"] = {}
        data["steps"][step_name] = new_json

    if last_step:
        data["output"] = new_json["output"]

    # Dump JSON back
    with open(status_json_fn, "w") as json_file:
        json.dump(data, json_file)


def nowf():
    return str(datetime.datetime.today().replace(microsecond=0))


def format_dict(cmd, result, returncode, inp, out, log, parameters=None):
    configs = config
    d = {}
    d['command'] = cmd
    d['result'] = result
    d['return_code'] = returncode
    d['config'] = configs
    d['input'] = {}
    d['log'] = log
    for name, value in inp.items():
        d['input'][name] = value
    d['output'] = {}
    for name, value in out.items():
        d['output'][name] = value
    d['params'] = {}
    if parameters is not None:
        for name, value in parameters.items():
            d['params'][name] = value
    d['time'] = nowf()
    return d


def update_local_and_global_jsons(json_file, status, step_name, cmdstr, result, returncode, inp, out, log, par=None, last_step=False):
    json_dict = format_dict(cmdstr, result, returncode, inp, out, log, par)
    json.dump(json_dict, json_file)
    update_status(status, step_name, json_dict, last_step)


# Run KMC
rule kmc:
    input:
        sample = sample_config
    output:
        kmc_out = pjoin(kmc_dir, "kmers.kmc_pre")
    params:
        kmc_prefix = pjoin(kmc_dir, "kmers"),
        kmc_tmp = pjoin(kmc_dir, "tmp"),
        minocc = minocc_config,
        maxocc = maxocc_config,
        lenkmers = malvak_config,
        maxmem = maxmem_config
    threads: int(cores_config)
    log:
        out = pjoin(kmc_dir, "kmc.log"),
        json = pjoin(kmc_dir, "kmc.json")
    run:
        update_status("Running")
        step_name = "KMC"
        shell("mkdir -p {params.kmc_tmp}")
        cmdstr = f"kmc -t{threads} -m{params.maxmem} -k{params.lenkmers} -ci{params.minocc} -cs{params.maxocc} -fm {input.sample} {params.kmc_prefix} {params.kmc_tmp} &> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                shell("rm -fr {params.kmc_tmp}")
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Running", step_name, cmdstr, "Success", 0,
                                              input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                shell("rm -fr {params.kmc_tmp}")
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e

# Run MALVA
rule malva:
    input:
        ref = ref_config,
        vcf = vcf_config,
        kmc = pjoin(kmc_dir, "kmers.kmc_pre")
    params:
        kmc_prefix = pjoin(kmc_dir, "kmers"),
        k = malvak_config,
        c = maxocc_config,
        bfsize = malva_bf_size
    output:
        vcf = pjoin(malva_dir, "malva.non_tagged.vcf")
    threads: 1
    log:
        out = pjoin(malva_dir, "malva.log"),
        json = pjoin(malva_dir, "malva.json")
    run:
        step_name = "malva"
        cmdstr = f"/software/malva/malva-geno -1 -k {params.k} -c {params.c} -b {params.bfsize} {input.ref} {input.vcf} {params.kmc_prefix} > {output.vcf} 2> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Running", step_name, cmdstr, "Success", 0,
                                              input, output, log_out, params, True)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e

# Tag VCF
rule tag_malva_vcf:
    input:
        vcf = pjoin(malva_dir, "malva.non_tagged.vcf")
    output:
        vcf = pjoin(malva_dir, "malva.vcf")
    params:
        gtf = gtf_config
    threads: 1
    log:
        out = pjoin(tagvcf_dir, "tag_vcf.log"),
        json = pjoin(tagvcf_dir, "tag_vcf.json")
    run:
        step_name = "tagvcf"
        cmdstr = f"tag_vcf.py -a {input.vcf} {params.gtf} > {output.vcf} 2> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Running", step_name, cmdstr, "Success", 0,
                                              input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e

# Ease MALVA vcf
rule ease_malva_vcf:
    input:
        vcf = pjoin(malva_dir, "malva.vcf")
    output:
        vcf = pjoin(ease_dir, "malva.ease.vcf")
    threads: 1
    log:
        out = pjoin(ease_dir, "ease_vcf.log"),
        json = pjoin(ease_dir, "ease_vcf.json")
    run:
        step_name = "easevcf"
        cmdstr = f"ease_malva_vcf.py {input.vcf} > {output.vcf} 2> {log.out}"
        with open(log.json, 'w') as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Running", step_name, cmdstr, "Success", 0,
                                              input, output, log_out)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out)
                raise e

# Run snpeff
rule snpeff:
    input:
        vcf = pjoin(ease_dir, "malva.ease.vcf")
    output:
        vcf = pjoin(snpeff_dir, "snpeff.vcf")
    params:
        refname = refname_config
    threads:
        1
    log:
        out = pjoin(snpeff_dir, "snpeff.log"),
        json = pjoin(snpeff_dir, "snpeff.json")
    run:
        if params.refname is None:
            cmdstr = f"cp {input.vcf} {output.vcf} 2> {log.out}"
        else:
            cmdstr = f"snpEff -noLog -noStats -ud 0 -no-downstream -no-intergenic -no-upstream -no-utr -v {params.refname} {input.vcf} > {output.vcf} 2> {log.out}"
        with open(log.json, 'w') as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Completed" if rule == config["target_rule"] else "Running", rule, cmdstr, "Success", 0,
                                              input, output, log_out, params, last_step = True)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", rule, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e

# Compress and index the resulting VCF
rule bcftools_gzip:
    input:
        vcf = pjoin(snpeff_dir, "snpeff.vcf"),
    output:
        vcf = temp(pjoin(pangolin_dir, "snpeff.vcf.gz")),
        csi = temp(pjoin(pangolin_dir, "snpeff.vcf.gz.csi")),
    log:
        out = pjoin(pangolin_dir, "bcftools_gzip.log"),
        json = pjoin(pangolin_dir, "bcftools_gzip.json")
    threads: 1
    run:
        cmdstr = f"/opt/conda/bin/conda run --no-capture-output -n bcftools bgzip --threads {threads} -c {input.vcf} > {output.vcf} 2> {log.out} && /opt/conda/bin/conda run --no-capture-output -n bcftools bcftools index --threads {threads} {output.vcf} 2>> {log.out}"
        with open(log.json, 'w') as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Completed" if rule == config["target_rule"] else "Running", rule, cmdstr, "Success", 0,
                                              input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", rule, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e


# Translate the VCF into a FASTA file
rule consensus:
    input:
        vcf = pjoin(pangolin_dir, "snpeff.vcf.gz"),
        csi = pjoin(pangolin_dir, "snpeff.vcf.gz.csi"),
    output:
        consensus = temp(pjoin(pangolin_dir, "consensus.fa")),
    params:
        ref = ref_config,
    threads: 1
    log:
        out = pjoin(pangolin_dir, "consensus.log"),
        json = pjoin(pangolin_dir, "consensus.json")
    threads: 1
    run:
        cmdstr = f"/opt/conda/bin/conda run --no-capture-output -n bcftools bcftools consensus -H 1 -f {params.ref} {input.vcf} > {output.consensus} 2> {log.out}"
        with open(log.json, 'w') as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Completed" if rule == config["target_rule"] else "Running", rule, cmdstr, "Success", 0,
                                              input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", rule, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e


# Assign the lineage of the full length genomic sequence
rule pangolin_pred:
    input:
        consensus = pjoin(pangolin_dir, "consensus.fa"),
    output:
        lineage = pjoin(pangolin_dir, "lineage.csv"),
        global_lineage = pjoin(pangolin_dir, "global_lineage_information.csv"),
    threads: 1
    log:
        out = pjoin(pangolin_dir, "pangolin_pred.log"),
        json = pjoin(pangolin_dir, "pangolin_pred.json")
    shadow: "minimal"
    run:
        cmdstr = f"/opt/conda/bin/conda run --no-capture-output -n pangolin pangolin --outfile {output.lineage} --panGUIlin --threads {threads} {input.consensus} &> {log.out} && mv global_lineage_information.csv {output.global_lineage} &>> {log.out}"
        with open(log.json, 'w') as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Completed" if rule == config["target_rule"] else "Running", rule, cmdstr, "Success", 0,
                                              input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", rule, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e


rule pangolin:
    input: rules.pangolin_pred.output
    output: pjoin(root_dir, 'pangolin.json')
    threads: 1
    log:
        out = pjoin(pangolin_dir, "pangolin.log"),
        json = pjoin(pangolin_dir, "pangolin.json")
    run:
        cmdstr = f"csvjoin {input} | csvjson --stream > {output} 2> {log.out}"
        with open(log.json, 'w') as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Completed" if rule == config["target_rule"] else "Running", rule, cmdstr, "Success", 0,
                                                input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", rule, cmdstr, "Failed", e.returncode,
                                                input, output, log_out, params)
                raise e
