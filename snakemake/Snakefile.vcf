import re
import json
import subprocess
import datetime
import os
configfile: "config.vcf.yaml"


pjoin = os.path.join

reference_path = config["reference"]  # single sequence to be used as reference
references_path = config["multifa"]  # all other sequences

root_dir = config["workdir"]
mafft_dir = pjoin(root_dir, "mafft")
snpsites_dir = pjoin(root_dir, "snpsites")
fa_index_dir = pjoin(root_dir, "faindex")
clean_vcf_dir = pjoin(root_dir, "vcf")

cores_config = config["cores"] if "cores" in config else 4

status_json_fn = pjoin(root_dir, "status.json")


def update_status(new_status, step_name=None, new_json=None, last_step=False):
    # Load JSON
    try:
        with open(status_json_fn) as json_file:
            data = json.load(json_file)
    except FileNotFoundError as e:
        data = {}

    # Update status and steps
    data["status"] = new_status
    data["last_time"] = nowf()
    if new_json:
        if "steps" not in data:
            data["steps"] = {}
        data["steps"][step_name] = new_json

    if last_step:
        data["output"] = new_json["output"]

    # Dump JSON back
    with open(status_json_fn, "w") as json_file:
        json.dump(data, json_file)


def nowf():
    return str(datetime.datetime.today().replace(microsecond=0))


def format_dict(cmd, result, returncode, inp, out, log, parameters=None):
    configs = config
    d = {}
    d['command'] = cmd
    d['result'] = result
    d['return_code'] = returncode
    d['config'] = configs
    d['input'] = {}
    d['log'] = log
    for name, value in inp.items():
        d['input'][name] = value
    d['output'] = {}
    for name, value in out.items():
        d['output'][name] = value
    d['params'] = {}
    if parameters is not None:
        for name, value in parameters.items():
            d['params'][name] = value
    d['time'] = nowf()
    return d


def update_local_and_global_jsons(json_file, status, step_name, cmdstr, result, returncode, inp, out, log, par=None, last_step=False):
    json_dict = format_dict(cmdstr, result, returncode, inp, out, log, par)
    json.dump(json_dict, json_file)
    update_status(status, step_name, json_dict, last_step)


rule run:
    input:
        pjoin(clean_vcf_dir, "run.cleaned.vcf")

# Multi alignment with mafft
rule multi_align:
    input:
        fa = reference_path,
        mfa = references_path
    output:
        msa = pjoin(mafft_dir, "multi_alignment.msa")
    threads: int(cores_config)
    log:
        out = pjoin(mafft_dir, "mafft.log"),
        json = pjoin(mafft_dir, "mafft.json")
    run:
        update_status("Running")
        step_name = "mafft"
        cmdstr = f"mafft --thread {threads} --auto --keeplength --addfragments {input.mfa} {input.fa} > {output.msa} 2> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(
                    jf, "Running", step_name, cmdstr, "Success", 0, input, output, log_out, None)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, None)
                raise e

# Create vcf from multi alignment
rule vcf_build:
    input:
        msa = pjoin(mafft_dir, "multi_alignment.msa")
    output:
        snps = pjoin(snpsites_dir, "run.vcf")
    params:
        prefix = pjoin(snpsites_dir, "run")
    threads: 1
    log:
        out = pjoin(snpsites_dir, "snpsites.log"),
        json = pjoin(snpsites_dir, "snpsites.json")
    run:
        step_name = "snpsites"
        cmdstr = f"snp-sites -rmcv -o {params.prefix} {input.msa} &> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(
                    jf, "Running", step_name, cmdstr, "Success", 0, input, output, log_out, params)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, params)
                raise e

# Clean VCF header fixing repeated sample ids (maybe useless. But it was common with GISAID)
rule vcf_clean_header:
    input:
        base_vcf = pjoin(snpsites_dir, "run.vcf")
    output:
        clean_vcf = temp(pjoin(clean_vcf_dir, "run.1.vcf"))
    threads: 1
    log:
        out = pjoin(clean_vcf_dir, "vcf_clean.1.log"),
        json = pjoin(clean_vcf_dir, "vcf_clean.1.json")
    run:
        step_name = "vcf_clean_header"
        cmdstr = f"format_vcf.py clean {input.base_vcf} | cut -f 1-9,11- > {output.clean_vcf} 2> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(
                    jf, "Running", step_name, cmdstr, "Success", 0, input, output, log_out, None)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, None)
                raise e

# Index input reference
rule index_reference:
    input:
        fa = reference_path
    output:
        fa_idx = reference_path + ".fai"
    threads: 1
    log:
        out = pjoin(fa_index_dir, "fa_index.log"),
        json = pjoin(fa_index_dir, "fa_index.json")
    run:
        step_name = "fa_index"
        cmdstr = f"samtools faidx {input.fa} 2> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(
                    jf, "Running", step_name, cmdstr, "Success", 0, input, output, log_out, None)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, None)
                raise e

# Computes a priori frequencies
rule vcf_add_freqs:
    input:
        clean_vcf = pjoin(clean_vcf_dir, "run.1.vcf"),
        fa_idx = reference_path + ".fai"
    output:
        freq_vcf = pjoin(clean_vcf_dir, "run.cleaned.vcf")
    threads: 1
    log:
        out = pjoin(clean_vcf_dir, "vcf_clean.2.log"),
        json = pjoin(clean_vcf_dir, "vcf_clean.2.json")
    run:
        step_name = "vcf_add_freqs"
        cmdstr = f"format_vcf.py freq {input.clean_vcf} {input.fa_idx} > {output.freq_vcf} 2> {log.out}"
        with open(log.json, "w") as jf:
            try:
                shell.check_output(cmdstr)
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Completed", step_name, cmdstr, "Success", 0,
                                              input, output, log_out, None, True)
            except subprocess.CalledProcessError as e:
                with open(log.out, 'r') as fin:
                    log_out = fin.read()
                update_local_and_global_jsons(jf, "Failed", step_name, cmdstr, "Failed", e.returncode,
                                              input, output, log_out, None)
                raise e
